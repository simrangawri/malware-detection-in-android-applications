# -*- coding: utf-8 -*-
"""malware detection final code.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/18NDwJ0JPcZPCFLMCTTTqMmagI7BR5IHk
"""

pip install scikit-learn==1.0.1

from sklearn.naive_bayes import GaussianNB, BernoulliNB
from sklearn.metrics import accuracy_score, classification_report
from sklearn.ensemble import BaggingClassifier
from sklearn.neighbors import KNeighborsClassifier
from sklearn.linear_model import SGDClassifier
from sklearn.model_selection import train_test_split
from sklearn.metrics import cohen_kappa_score
from sklearn.metrics import confusion_matrix
from sklearn.ensemble import RandomForestClassifier

from sklearn import preprocessing
import torch
from sklearn import svm
from sklearn import tree
import pandas as pd
#from sklearn.externals import joblib
import pickle
import numpy as np
import seaborn as sns

from sklearn.metrics import f1_score
from sklearn.metrics import precision_score
from sklearn.metrics import recall_score
from sklearn.metrics import average_precision_score
from sklearn.metrics import precision_recall_curve
import matplotlib.pyplot as plt

from sklearn.pipeline import make_pipeline
from sklearn.model_selection import cross_val_score

from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense, Flatten, Conv2D, MaxPooling2D,Dropout
from tensorflow.keras.losses import sparse_categorical_crossentropy
from tensorflow.keras.optimizers import Adam
from sklearn.model_selection import KFold
from sklearn.svm import SVR
from sklearn.preprocessing import MinMaxScaler
from sklearn.metrics import confusion_matrix,accuracy_score,precision_score,f1_score
from collections import Counter
from imblearn.over_sampling import SMOTE
from sklearn.metrics import brier_score_loss
from sklearn.metrics import roc_auc_score

from sklearn.feature_selection import SelectKBest
from sklearn.feature_selection import chi2

df=pd.read_excel('/content/data.xlsx')
df=df.drop('Name', axis=1)
df=df.drop('md5', axis=1)
df

df.shape

df = df.astype("int64")
df

X_train, X_test, y_train, y_test = train_test_split(df.iloc[:, 0:54], df['legitimate'], test_size=0.20, random_state=42)
print(type(X_test))

X_train=df.iloc[:, 0:54]
y_train=df['legitimate']
gnb = GaussianNB()

def custom_cross_validation1(model, X_train, y_train, cv):
    my_pipeline = make_pipeline(Imputer(), model)
    scores = cross_val_score(my_pipeline, X_train, y_train, cv=cv)
    print("%0.2f accuracy with a standard deviation of %0.2f" % (scores.mean(), scores.std()))
    return scores

X_train



def r2(y_true,y_pred):
    m_t_v=np.mean(y_true)
    numerator=0
    denominator=0
    for yt,yp in zip(y_true,y_pred):
        numerator +=(yt-yp)**2
        denominator +=(yt-m_t_v)**2
    r=numerator/denominator
    return 1-r

def mcc(y_true,y_pred):
    #tp=true_positive(y_true,y_pred)
    #tn=true_negative(y_true,y_pred)
    #fp=false_positive(y_true,y_pred)
    #fn=false_negative(y_true,y_pred)
    tn, fp, fn, tp = confusion_matrix(y_true,y_pred).ravel()
    n=(tp*tn)-(fp*fn)
    d=((tp+fp)*(fn+tn)*(fp+tn)*(tp+fn))
    d=d**0.5
    r=n/d
    return r

def scoreset(y_true,y_pred):
    score_set=[]
    pred=y_pred
    y_test=y_true
    print("cohen kappa score",cohen_kappa_score(y_test, pred))
    score_set.append(cohen_kappa_score(y_test, pred))
    print("cohen kappa score quadratic",cohen_kappa_score(y_test, pred, weights="quadratic"))
    score_set.append(cohen_kappa_score(y_test, pred, weights="quadratic"))
    print("R square score", r2(y_test,pred))
    score_set.append(r2(y_test,pred))
    print("MCC score", mcc(y_test,pred))
    score_set.append(mcc(y_test,pred))
    print("Brier Score Loss",brier_score_loss(y_test, pred))
    score_set.append(brier_score_loss(y_test, pred))
    print("AUC ROC Score",roc_auc_score(y_test, pred))
    score_set.append(roc_auc_score(y_test, pred))
    print("")
    print("accuracy:",accuracy_score(y_test,pred))
    score_set.append(accuracy_score(y_test,pred))
    print("F1 Score:",f1_score(y_test,pred))
    score_set.append(f1_score(y_test,pred))
    print("Precision:",precision_score(y_test,pred))
    score_set.append(precision_score(y_test,pred))
    print("Recall:",recall_score(y_test,pred))
    score_set.append(recall_score(y_test,pred))
    return score_set

# Naive Bayes algorithm
gnb = GaussianNB()
gnb.fit(X_train, y_train)

# pred
pred = gnb.predict(X_test)

# accuracy
accuracy = accuracy_score(pred, y_test)
print("naive_bayes")
print(classification_report(pred, y_test, labels=None))




s=scoreset(y_test,pred)

# kneighbors algorithm

for i in range(3,15,3):

    neigh = KNeighborsClassifier(n_neighbors=i)
    neigh.fit(X_train, y_train)
    pred = neigh.predict(X_test)
    # accuracy
    accuracy = accuracy_score(pred, y_test)
    print("kneighbors {}".format(i))
    print(accuracy)
    print(classification_report(pred, y_test, labels=None))
    s=scoreset(y_test,pred)
    print(type(pred))

tr_acc = []
ts_acc = []
for i in range(1,21):
  kms = KNeighborsClassifier(n_neighbors=i)
  kms.fit(X_train,y_train)

  tr_acc.append(kms.score(X_train,y_train))
  ts_acc.append(kms.score(X_test,y_test))
  import matplotlib.pyplot as plt
plt.plot(range(1,21),tr_acc)
plt.plot(range(1,21),ts_acc,c='r')
plt.show()

clf = tree.DecisionTreeClassifier()
clf.fit(X_train, y_train)

# Read the csv test file

pred = clf.predict(X_test)
# accuracy
accuracy = accuracy_score(pred, y_test)
print(clf)
print(accuracy)
print(classification_report(pred, y_test, labels=None))
s=scoreset(y_test,pred)

from sklearn.tree import export_graphviz
from IPython.display import Image
import pydotplus

dot_data = export_graphviz(clf,feature_names=X_train.columns)
graph = pydotplus.graph_from_dot_data(dot_data)
Image(graph.create_png())

#LinearSVM
from sklearn import svm

lin_clf = svm.LinearSVC()
lin_clf.fit(X_train, y_train)
pred = lin_clf.predict(X_test)
# accuracy
accuracy = accuracy_score(pred, y_test)
print(accuracy)
print(classification_report(pred, y_test, labels=None))
s=scoreset(y_test,pred)

import pickle
pickle_out = open("classifier.pkl","wb")
pickle.dump(lin_clf,pickle_out)
pickle_out.close()

import numpy as np
import joblib
print(neigh.predict([[34404,240,8226,14,12,779776,253952,0,56256,4096,0,6442450944,4096,512,10,0,10,0,10,0,1052672,1024,1064956,2,16736,262144,4096,1048576,4096,0,16,7,4.43312330617,2.05589439683,6.42707999534,147090.285714,1024,779776,147420.571429,752,779318,62,285,7,3,2,3.07205024587,2.7068325827,3.43726790904,604.0,200,1008,256,16]]))

def predict_malware(Machine,SizeOfOptionalHeader,Characteristics,MajorLinkerVersion,MinorLinkerVersion,SizeOfCode,SizeOfInitializedData,SizeOfUninitializedData,AddressOfEntryPoint,BaseOfCode,BaseOfData,ImageBase,SectionAlignment,FileAlignment,MajorOperatingSystemVersion,MinorOperatingSystemVersion,MajorImageVersion,MinorImageVersion,MajorSubsystemVersion,MinorSubsystemVersion,SizeOfImage,SizeOfHeaders,CheckSum,Subsystem,DllCharacteristics,SizeOfStackReserve,SizeOfStackCommit,SizeOfHeapReserve,SizeOfHeapCommit,LoaderFlags,NumberOfRvaAndSizes,SectionsNb,SectionsMeanEntropy,SectionsMinEntropy,SectionsMaxEntropy,SectionsMeanRawsize,SectionsMinRawsize,SectionMaxRawsize,SectionsMeanVirtualsize,SectionsMinVirtualsize,SectionMaxVirtualsize,ImportsNbDLL,ImportsNb,ImportsNbOrdinal,ExportNb,ResourcesNb,ResourcesMeanEntropy,ResourcesMinEntropy,ResourcesMaxEntropy,ResourcesMeanSize,ResourcesMinSize,ResourcesMaxSize,LoadConfigurationSize,VersionInformationSize):

  uv = np.zeros(X_train.shape[1])
  uv[0] = Machine
  uv[1] = SizeOfOptionalHeader
  uv[2] = Characteristics
  uv[3] = MajorLinkerVersion
  uv[4] = MinorLinkerVersion
  uv[5] = SizeOfCode
  uv[6] = SizeOfInitializedData
  uv[7] = SizeOfUninitializedData
  uv[8] = AddressOfEntryPoint
  uv[9] = BaseOfCode
  uv[10] = BaseOfData
  uv[11] = ImageBase
  uv[12] = SectionAlignment
  uv[13] = FileAlignment
  uv[14] = MajorOperatingSystemVersion
  uv[15] = MinorOperatingSystemVersion
  uv[16] = MajorImageVersion
  uv[17] = MinorImageVersion
  uv[18] = MajorSubsystemVersion
  uv[19] = MinorSubsystemVersion
  uv[20] = SizeOfImage
  uv[21] = SizeOfHeaders
  uv[22] = CheckSum
  uv[23] = Subsystem
  uv[24] = DllCharacteristics
  uv[25] = SizeOfStackReserve
  uv[26] = SizeOfStackCommit
  uv[27] = SizeOfHeapReserve
  uv[28] = SizeOfHeapCommit
  uv[29] = LoaderFlags
  uv[30] = NumberOfRvaAndSizes
  uv[31] = SectionsNb
  uv[32] = SectionsMeanEntropy
  uv[33] = SectionsMinEntropy
  uv[34] = SectionsMaxEntropy
  uv[35] = SectionsMeanRawsize
  uv[36] = SectionsMinRawsize
  uv[37] = SectionMaxRawsize
  uv[38] = SectionsMeanVirtualsize
  uv[39] = SectionsMinVirtualsize
  uv[40] = SectionMaxVirtualsize
  uv[41] = ImportsNbDLL
  uv[42] = ImportsNb
  uv[43] = ImportsNbOrdinal
  uv[44] = ExportNb
  uv[45] = ResourcesNb
  uv[46] = ResourcesMeanEntropy
  uv[47] = ResourcesMinEntropy
  uv[48] = ResourcesMaxEntropy
  uv[49] = ResourcesMeanSize
  uv[50] = ResourcesMinSize
  uv[51] = ResourcesMaxSize
  uv[52] = LoadConfigurationSize
  uv[53] = VersionInformationSize





  return neigh.predict([uv])

Prections = np.array(['not Malware','Malware'])

print(predict_malware(34404,240,8226,14,12,779776,253952,0,56256,4096,0,6442450944,4096,512,10,0,10,0,10,0,1052672,1024,1064956,2,16736,262144,4096,1048576,4096,0,16,7,4.43312330617,2.05589439683,6.42707999534,147090.285714,1024,779776,147420.571429,752,779318,62,285,7,3,2,3.07205024587,2.7068325827,3.43726790904,604.0,200,1008,256,16))
print(Prections[np.argmax(predict_malware(34404,240,8226,14,12,779776,253952,0,56256,4096,0,6442450944,4096,512,10,0,10,0,10,0,1052672,1024,1064956,2,16736,262144,4096,1048576,4096,0,16,7,4.43312330617,2.05589439683,6.42707999534,147090.285714,1024,779776,147420.571429,752,779318,62,285,7,3,2,3.07205024587,2.7068325827,3.43726790904,604.0,200,1008,256,16))])